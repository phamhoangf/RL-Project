{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "papermill": {
      "default_parameters": {},
      "duration": 9835.268821,
      "end_time": "2024-11-29T15:18:37.899348",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-11-29T12:34:42.630527",
      "version": "2.6.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/Farama-Foundation/MAgent2"
      ],
      "metadata": {
        "_uuid": "9f669fae-8bbf-4420-82db-a1d43583e10b",
        "_cell_guid": "0ca7c070-3846-438e-a43d-3eb9c508e95d",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T05:46:56.698057Z",
          "iopub.execute_input": "2024-12-10T05:46:56.698526Z",
          "iopub.status.idle": "2024-12-10T05:47:39.013900Z",
          "shell.execute_reply.started": "2024-12-10T05:46:56.698480Z",
          "shell.execute_reply": "2024-12-10T05:47:39.012640Z"
        },
        "papermill": {
          "duration": 33.272312,
          "end_time": "2024-11-29T12:35:19.024067",
          "exception": false,
          "start_time": "2024-11-29T12:34:45.751755",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsQFcJrPsSUb",
        "outputId": "de21bff3-8e62-4e33-a934-73e181391eb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Farama-Foundation/MAgent2\n",
            "  Cloning https://github.com/Farama-Foundation/MAgent2 to /tmp/pip-req-build-3fk0th1j\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Farama-Foundation/MAgent2 /tmp/pip-req-build-3fk0th1j\n",
            "  Resolved https://github.com/Farama-Foundation/MAgent2 to commit b2ddd49445368cf85d4d4e1edcddae2e28aa1406\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from magent2==0.3.3) (1.26.4)\n",
            "Requirement already satisfied: pygame>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from magent2==0.3.3) (2.6.1)\n",
            "Collecting pettingzoo>=1.23.1 (from magent2==0.3.3)\n",
            "  Downloading pettingzoo-1.24.3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting gymnasium>=0.28.0 (from pettingzoo>=1.23.1->magent2==0.3.3)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.28.0->pettingzoo>=1.23.1->magent2==0.3.3)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Building wheels for collected packages: magent2\n",
            "  Building wheel for magent2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for magent2: filename=magent2-0.3.3-cp310-cp310-linux_x86_64.whl size=1696112 sha256=f3eabaecb3de014eaaa06cbcecd7d4cc677b920ae66f698c4b395514a9e284d2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b6c410tu/wheels/e4/8e/bf/51a30bc4038546e23b81c9fb513fe6a8fd916e5a9c5f4291d5\n",
            "Successfully built magent2\n",
            "Installing collected packages: farama-notifications, gymnasium, pettingzoo, magent2\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0 magent2-0.3.3 pettingzoo-1.24.3\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "_uuid": "16c64144-219c-481f-8ab0-f90a296adcf9",
        "_cell_guid": "33b7d2f1-992b-499d-a66f-e17b8c33fc16",
        "trusted": true,
        "collapsed": false,
        "papermill": {
          "duration": 0.007022,
          "end_time": "2024-11-29T12:35:19.038519",
          "exception": false,
          "start_time": "2024-11-29T12:35:19.031497",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "V6K8st1DsSUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from magent2.environments import battle_v4\n",
        "import cv2\n",
        "from collections import deque\n",
        "import time\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "_uuid": "c883fe15-8130-45da-bc82-cee736639626",
        "_cell_guid": "6e79a227-b85d-40ca-a3d1-7698943a7cce",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T04:47:02.676274Z",
          "iopub.execute_input": "2024-12-10T04:47:02.676565Z",
          "iopub.status.idle": "2024-12-10T04:47:06.096228Z",
          "shell.execute_reply.started": "2024-12-10T04:47:02.676532Z",
          "shell.execute_reply": "2024-12-10T04:47:06.095558Z"
        },
        "papermill": {
          "duration": 4.648022,
          "end_time": "2024-11-29T12:35:23.693477",
          "exception": false,
          "start_time": "2024-11-29T12:35:19.045455",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "po2mzBoFsSUg"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DQN"
      ],
      "metadata": {
        "_uuid": "18082222-bd6e-474f-ac3a-099bedc5c252",
        "_cell_guid": "6703be23-ffc9-4944-8e18-f400e2729588",
        "trusted": true,
        "collapsed": false,
        "papermill": {
          "duration": 0.006838,
          "end_time": "2024-11-29T12:35:23.918227",
          "exception": false,
          "start_time": "2024-11-29T12:35:23.911389",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "qsvHiL9rsSUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, observation_shape, action_shape, device='cpu'):\n",
        "        super().__init__()\n",
        "        self.observation_shape = observation_shape\n",
        "        self.action_shape = action_shape\n",
        "        self.device = device\n",
        "\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(observation_shape[-1], observation_shape[-1], kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(observation_shape[-1], observation_shape[-1], kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        dummy_input = torch.randn(observation_shape).permute(2, 0, 1)\n",
        "        dummy_output = self.cnn(dummy_input)\n",
        "        flatten_dim = dummy_output.view(-1).shape[0]\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(flatten_dim, 120),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(120, 84),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(84, action_shape),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert len(x.shape) >= 3, \"only support magent input observation\"\n",
        "        x = self.cnn(x)\n",
        "        if len(x.shape) == 3:\n",
        "            batchsize = 1\n",
        "        else:\n",
        "            batchsize = x.shape[0]\n",
        "        x = x.reshape(batchsize, -1)\n",
        "        return self.network(x)"
      ],
      "metadata": {
        "_uuid": "0a512c1f-83c6-45ca-a415-1ee87d13f995",
        "_cell_guid": "bcc09ca2-7170-4808-bd86-d1a66314a096",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T04:47:06.106982Z",
          "iopub.execute_input": "2024-12-10T04:47:06.107748Z",
          "iopub.status.idle": "2024-12-10T04:47:06.121317Z",
          "shell.execute_reply.started": "2024-12-10T04:47:06.107721Z",
          "shell.execute_reply": "2024-12-10T04:47:06.120614Z"
        },
        "papermill": {
          "duration": 0.018182,
          "end_time": "2024-11-29T12:35:23.952303",
          "exception": false,
          "start_time": "2024-11-29T12:35:23.934121",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "4uWvLuKvsSUk"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replay Buffer"
      ],
      "metadata": {
        "_uuid": "a05e439f-cda6-4eaf-8cfe-1dd28006bae2",
        "_cell_guid": "5268250c-7bb4-4786-b50f-2b747dad0961",
        "trusted": true,
        "collapsed": false,
        "papermill": {
          "duration": 0.007009,
          "end_time": "2024-11-29T12:35:23.856757",
          "exception": false,
          "start_time": "2024-11-29T12:35:23.849748",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "MgdKXxwCsSUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayMemory(Dataset):\n",
        "    def __init__(self, maxlen):\n",
        "        super().__init__()\n",
        "        self.maxlen = maxlen\n",
        "        self.step_memory = [deque([],maxlen=self.maxlen)]\n",
        "\n",
        "    def push(self, step_idx, state, action, reward, next_state, done):\n",
        "        if step_idx == len(self.step_memory):\n",
        "            self.step_memory.append(deque([],maxlen=self.maxlen))\n",
        "        self.step_memory[step_idx].append((state, action, reward, next_state, done))\n",
        "\n",
        "    def __len__(self):\n",
        "        return sum([len(memory) for memory in self.step_memory])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        step_idx = 0\n",
        "        while idx >= len(self.step_memory[step_idx]):\n",
        "            idx -= len(self.step_memory[step_idx])\n",
        "            step_idx += 1\n",
        "        state, action, reward, next_state, done = self.step_memory[step_idx][idx]\n",
        "        return (\n",
        "            torch.Tensor(state).float().permute([2, 0, 1]),\n",
        "            torch.tensor(action),\n",
        "            torch.tensor(reward, dtype=torch.float),\n",
        "            torch.tensor(next_state).float().permute([2,0,1]),\n",
        "            torch.tensor(done, dtype=torch.float32),\n",
        "        )"
      ],
      "metadata": {
        "_uuid": "dd69371c-5c95-47e2-8b92-d93980dcbd8b",
        "_cell_guid": "3bb31d47-4f74-44a8-9980-752944ffb4b0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T04:47:06.097129Z",
          "iopub.execute_input": "2024-12-10T04:47:06.097448Z",
          "iopub.status.idle": "2024-12-10T04:47:06.104863Z",
          "shell.execute_reply.started": "2024-12-10T04:47:06.097424Z",
          "shell.execute_reply": "2024-12-10T04:47:06.104072Z"
        },
        "papermill": {
          "duration": 0.019958,
          "end_time": "2024-11-29T12:35:23.883672",
          "exception": false,
          "start_time": "2024-11-29T12:35:23.863714",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "Lr6mxiaZsSUi"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer"
      ],
      "metadata": {
        "_uuid": "ea925093-c460-41c3-958a-9d168e3949d9",
        "_cell_guid": "7a6b1f2b-5085-47e6-b902-b115008d6dd7",
        "trusted": true,
        "collapsed": false,
        "papermill": {
          "duration": 0.006993,
          "end_time": "2024-11-29T12:35:23.966416",
          "exception": false,
          "start_time": "2024-11-29T12:35:23.959423",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "_DOd5Mg-sSUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        policy_dqn, target_dqn,\n",
        "        n_action,\n",
        "        loss_fn, optimizer, scheduler,\n",
        "        epsilon_start, epsilon_end, epsilon_decay,\n",
        "        device='cpu'\n",
        "    ):\n",
        "\n",
        "        self.policy_dqn = policy_dqn.to(device)\n",
        "        self.target_dqn = target_dqn.to(device)\n",
        "        self.target_dqn.eval()\n",
        "\n",
        "        self.n_action = n_action\n",
        "\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "        self.epsilon_start = epsilon_start\n",
        "        self.epsilon_end = epsilon_end\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon = self.epsilon_start\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.policy_dqn.apply(self.weights_init)\n",
        "\n",
        "    def weights_init(self, m):\n",
        "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            if torch.is_tensor(m.bias):\n",
        "                m.bias.data.fill_(0.01)\n",
        "\n",
        "\n",
        "    def policy(self, observation):\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return np.random.randint(low=0, high=self.n_action)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                q_values = self.policy_dqn(\n",
        "                    torch.Tensor(observation).float().permute([2, 0, 1]).unsqueeze(0).to(self.device)\n",
        "                )\n",
        "            return torch.argmax(q_values, dim=1).cpu().numpy()[0]\n",
        "\n",
        "\n",
        "    def optimize_model(self, replay_memory, batch_size, gamma):\n",
        "        if len(replay_memory) < batch_size:\n",
        "            return\n",
        "        train_loader = DataLoader(replay_memory, batch_size=batch_size, shuffle=True)\n",
        "        self.policy_dqn.train()\n",
        "\n",
        "        for observations, actions, rewards, next_observations, dones in train_loader:\n",
        "\n",
        "            self.policy_dqn.zero_grad()\n",
        "\n",
        "            observations = observations.to(self.device)\n",
        "            actions = actions.unsqueeze(1).to(self.device)\n",
        "            rewards = rewards.unsqueeze(1).to(self.device)\n",
        "            next_observations = next_observations.to(self.device)\n",
        "            dones = dones.unsqueeze(1).to(self.device)\n",
        "\n",
        "            current_q_values = self.policy_dqn(observations).gather(1, actions)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                target_q_values = rewards + gamma * (1 - dones) * self.target_dqn(next_observations).max(1, keepdim=True)[0]\n",
        "\n",
        "            # Compute loss\n",
        "            loss = self.loss_fn(current_q_values, target_q_values)\n",
        "\n",
        "            # Optimize the network\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.scheduler.step()\n",
        "\n",
        "    def train(self,\n",
        "              env, episodes,\n",
        "              target_agent, batch_size, gamma, replay_memory,\n",
        "              update_tg_freq, TAU\n",
        "             ):\n",
        "        train_rewards = []\n",
        "        train_durations = []\n",
        "\n",
        "        for episode in tqdm(range(episodes)):\n",
        "            ep_reward = 0\n",
        "\n",
        "            ep_steps = 0\n",
        "\n",
        "            observations = {}\n",
        "            actions = {}\n",
        "            step_idx = {}\n",
        "\n",
        "            env.reset()\n",
        "\n",
        "            for idx, agent in enumerate(env.agent_iter()):\n",
        "                ep_steps += 1\n",
        "                observation, reward, termination, truncation, info = env.last()\n",
        "\n",
        "                if target_agent in agent:\n",
        "                    ep_reward += reward\n",
        "                else:\n",
        "                    ep_reward -= abs(reward)\n",
        "\n",
        "                step_idx[agent] = 0\n",
        "                action = self.policy(observation)\n",
        "\n",
        "                observations[agent] = observation\n",
        "                actions[agent] = action\n",
        "                env.step(action)\n",
        "\n",
        "                if (idx+1) % env.num_agents == 0:\n",
        "                    break\n",
        "\n",
        "            for agent in env.agent_iter():\n",
        "                ep_steps += 1\n",
        "\n",
        "                next_observation, reward, termination, truncation, info = env.last()\n",
        "\n",
        "                if target_agent in agent:\n",
        "                    ep_reward += reward\n",
        "                else:\n",
        "                    ep_reward -= abs(reward)\n",
        "\n",
        "                # Agent die\n",
        "                if termination or truncation:\n",
        "                    action = None\n",
        "                else:\n",
        "                    action = self.policy(next_observation)\n",
        "\n",
        "                replay_memory.push(\n",
        "                    step_idx[agent],\n",
        "                    observations[agent],\n",
        "                    actions[agent],\n",
        "                    reward,\n",
        "                    next_observation,\n",
        "                    termination or truncation\n",
        "                )\n",
        "\n",
        "                step_idx[agent] += 1\n",
        "                observations[agent] = next_observation\n",
        "                actions[agent] = action\n",
        "                env.step(action)\n",
        "\n",
        "            # Training mô hình với memory hiện tại\n",
        "            self.optimize_model(replay_memory, batch_size, gamma)\n",
        "\n",
        "            # Cập nhật lại mô hình mục tiêu theo chu kì\n",
        "            if episode % update_tg_freq == 0:\n",
        "                target_dqn_state_dict = self.target_dqn.state_dict()\n",
        "                policy_dqn_state_dict = self.policy_dqn.state_dict()\n",
        "                for key in policy_dqn_state_dict:\n",
        "                    target_dqn_state_dict[key] = policy_dqn_state_dict[key]*TAU + target_dqn_state_dict[key]*(1-TAU)\n",
        "                self.target_dqn.load_state_dict(target_dqn_state_dict)\n",
        "\n",
        "\n",
        "            self.epsilon = max(self.epsilon_end, self.epsilon * self.epsilon_decay)\n",
        "\n",
        "            print(f\"\\nEpisode {episode + 1}, Episode Reward: {ep_reward}, Steps: {ep_steps}, Epsilon: {self.epsilon}\")\n",
        "\n",
        "            train_rewards.append(ep_reward)\n",
        "            train_durations.append(ep_steps)\n",
        "\n",
        "        return train_rewards, train_durations"
      ],
      "metadata": {
        "_uuid": "ce1cfb8d-3448-49b2-902b-8af2718ae2e4",
        "_cell_guid": "f904b6bb-dd38-48de-b513-97fdce2f901f",
        "execution": {
          "iopub.status.busy": "2024-12-10T04:47:06.122440Z",
          "iopub.execute_input": "2024-12-10T04:47:06.122779Z",
          "iopub.status.idle": "2024-12-10T04:47:06.144932Z",
          "shell.execute_reply.started": "2024-12-10T04:47:06.122745Z",
          "shell.execute_reply": "2024-12-10T04:47:06.144240Z"
        },
        "papermill": {
          "duration": 0.037929,
          "end_time": "2024-11-29T12:35:24.011239",
          "exception": false,
          "start_time": "2024-11-29T12:35:23.973310",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "LmFWyL_usSUl"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "xWMfYGAdsSUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "env = battle_v4.env(map_size=45, render_mode=\"rgb_array\")\n",
        "\n",
        "episodes = 40\n",
        "target_agent = 'blue'\n",
        "batch_size = 1024\n",
        "gamma = 0.89\n",
        "update_tg_freq = 1\n",
        "TAU = 0.3\n",
        "\n",
        "maxlen = 162 * episodes\n",
        "\n",
        "learning_rate = 1e-3\n",
        "theta = 0.000001\n",
        "epsilon_start = 1.0\n",
        "epsilon_end = 0.01\n",
        "epsilon_decay = 0.9\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T04:47:06.145761Z",
          "iopub.execute_input": "2024-12-10T04:47:06.145971Z",
          "iopub.status.idle": "2024-12-10T04:47:06.245134Z",
          "shell.execute_reply.started": "2024-12-10T04:47:06.145950Z",
          "shell.execute_reply": "2024-12-10T04:47:06.244479Z"
        },
        "id": "O-LNgyXrsSUo"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T04:47:06.246132Z",
          "iopub.execute_input": "2024-12-10T04:47:06.246451Z",
          "iopub.status.idle": "2024-12-10T04:47:06.255188Z",
          "shell.execute_reply.started": "2024-12-10T04:47:06.246416Z",
          "shell.execute_reply": "2024-12-10T04:47:06.254439Z"
        },
        "id": "ph8bg0yUsSUp"
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop"
      ],
      "metadata": {
        "_uuid": "cc92f507-7093-427d-8a6f-0f361e37fd49",
        "_cell_guid": "7440a5b8-bead-475e-8185-cfc9a78ef083",
        "trusted": true,
        "collapsed": false,
        "papermill": {
          "duration": 0.006842,
          "end_time": "2024-11-29T12:35:24.025631",
          "exception": false,
          "start_time": "2024-11-29T12:35:24.018789",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "bsMx4KkzsSUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replay_memory = ReplayMemory(maxlen)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T04:47:06.256091Z",
          "iopub.execute_input": "2024-12-10T04:47:06.256334Z",
          "iopub.status.idle": "2024-12-10T04:47:06.263849Z",
          "shell.execute_reply.started": "2024-12-10T04:47:06.256304Z",
          "shell.execute_reply": "2024-12-10T04:47:06.263033Z"
        },
        "id": "tZd9oUAlsSUq"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "policy_dqn = QNetwork(env.observation_space(\"red_0\").shape, env.action_space(\"red_0\").n).to(device)\n",
        "target_dqn = QNetwork(env.observation_space(\"red_0\").shape, env.action_space(\"red_0\").n).to(device)\n",
        "target_dqn.load_state_dict(policy_dqn.state_dict())"
      ],
      "metadata": {
        "_uuid": "dfa412e7-acdc-407f-992a-d83e68b91cc7",
        "_cell_guid": "05b5ea12-a5db-44f7-a5ae-31cbda44a9bb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T04:47:06.264803Z",
          "iopub.execute_input": "2024-12-10T04:47:06.265041Z",
          "iopub.status.idle": "2024-12-10T04:47:06.539015Z",
          "shell.execute_reply.started": "2024-12-10T04:47:06.265018Z",
          "shell.execute_reply": "2024-12-10T04:47:06.538093Z"
        },
        "papermill": {
          "duration": 0.284104,
          "end_time": "2024-11-29T12:35:24.316848",
          "exception": false,
          "start_time": "2024-11-29T12:35:24.032744",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg8KvprxsSUr",
        "outputId": "512be2cd-c60d-440d-ff7d-80baec6d03c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(policy_dqn.parameters(), lr=learning_rate)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=episodes, eta_min=theta)"
      ],
      "metadata": {
        "_uuid": "30db65e6-dc02-4555-94b0-336a2e2474ec",
        "_cell_guid": "70b52fd4-7a08-4a94-8712-728182ce4420",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T04:47:06.542298Z",
          "iopub.execute_input": "2024-12-10T04:47:06.542659Z",
          "iopub.status.idle": "2024-12-10T04:47:07.359879Z",
          "shell.execute_reply.started": "2024-12-10T04:47:06.542631Z",
          "shell.execute_reply": "2024-12-10T04:47:07.359154Z"
        },
        "papermill": {
          "duration": 1.152042,
          "end_time": "2024-11-29T12:35:25.479407",
          "exception": false,
          "start_time": "2024-11-29T12:35:24.327365",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "dzXr2CaLsSUs"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainer = Trainer(\n",
        "    policy_dqn, target_dqn,\n",
        "    env.action_space(\"red_0\").n,\n",
        "    loss_function, optimizer, lr_scheduler,\n",
        "    epsilon_start, epsilon_end, epsilon_decay,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "_uuid": "183cf9b6-2ea5-4037-a206-777dc6b86694",
        "_cell_guid": "58579552-2c51-41e2-8961-08b83c5bc5f6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T04:47:07.360974Z",
          "iopub.execute_input": "2024-12-10T04:47:07.361440Z",
          "iopub.status.idle": "2024-12-10T04:47:07.398414Z",
          "shell.execute_reply.started": "2024-12-10T04:47:07.361397Z",
          "shell.execute_reply": "2024-12-10T04:47:07.397580Z"
        },
        "papermill": {
          "duration": 0.054528,
          "end_time": "2024-11-29T12:35:25.541611",
          "exception": false,
          "start_time": "2024-11-29T12:35:25.487083",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "JuZgCRyCsSUs"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_rewards, train_durations = trainer.train(\n",
        "    env, episodes,\n",
        "    target_agent, batch_size, gamma, replay_memory,\n",
        "    update_tg_freq, TAU\n",
        ")"
      ],
      "metadata": {
        "_uuid": "c24dc367-bdb4-4662-8c06-ef3c1dd41c98",
        "_cell_guid": "0ca0afe2-6b9e-4735-8843-eecef7f49550",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-10T04:48:24.653228Z",
          "iopub.execute_input": "2024-12-10T04:48:24.653670Z"
        },
        "papermill": {
          "duration": 9702.396059,
          "end_time": "2024-11-29T15:18:25.778310",
          "exception": false,
          "start_time": "2024-11-29T12:36:43.382251",
          "status": "completed"
        },
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3INdaN92sSUt",
        "outputId": "7ef9a0b1-1afe-4e86-aa95-e000cf728c54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▎         | 1/40 [00:53<34:40, 53.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 1, Episode Reward: -6647.125233091414, Steps: 158611, Epsilon: 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 2/40 [02:45<55:33, 87.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 2, Episode Reward: -6047.095206912607, Steps: 158669, Epsilon: 0.81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 3/40 [05:07<1:09:20, 112.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 3, Episode Reward: -3693.5851257890463, Steps: 105894, Epsilon: 0.7290000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 4/40 [07:36<1:16:16, 127.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 4, Episode Reward: -2363.1900751609355, Steps: 71251, Epsilon: 0.6561000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 5/40 [10:54<1:28:56, 152.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 5, Episode Reward: -4044.89513541013, Steps: 107790, Epsilon: 0.5904900000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 6/40 [14:35<1:39:39, 175.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 6, Episode Reward: -2555.2950820820406, Steps: 96029, Epsilon: 0.5314410000000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 7/40 [18:16<1:44:47, 190.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 7, Episode Reward: -1391.555031816475, Steps: 43618, Epsilon: 0.47829690000000014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 8/40 [21:54<1:46:22, 199.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 8, Episode Reward: -799.0200171433389, Steps: 24652, Epsilon: 0.43046721000000016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▎       | 9/40 [26:01<1:50:45, 214.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 9, Episode Reward: -1557.7200390445068, Steps: 64982, Epsilon: 0.38742048900000015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 10/40 [30:04<1:51:30, 223.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 10, Episode Reward: -450.9500146685168, Steps: 26464, Epsilon: 0.34867844010000015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 11/40 [34:14<1:51:51, 231.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 11, Episode Reward: -380.3900141045451, Steps: 28637, Epsilon: 0.31381059609000017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 12/40 [38:26<1:50:49, 237.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 12, Episode Reward: -466.28000976890326, Steps: 24160, Epsilon: 0.28242953648100017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▎      | 13/40 [42:49<1:50:21, 245.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 13, Episode Reward: -460.8950093910098, Steps: 26577, Epsilon: 0.25418658283290013\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 14/40 [47:36<1:51:46, 257.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 14, Episode Reward: -793.6000152053311, Steps: 49441, Epsilon: 0.22876792454961012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 15/40 [52:17<1:50:22, 264.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 15, Episode Reward: -176.27000698260963, Steps: 22390, Epsilon: 0.2058911320946491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 16/40 [56:54<1:47:26, 268.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 16, Episode Reward: -233.36000366602093, Steps: 15067, Epsilon: 0.1853020188851842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▎     | 17/40 [1:01:56<1:46:47, 278.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 17, Episode Reward: -634.4250093987212, Steps: 46693, Epsilon: 0.16677181699666577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 18/40 [1:06:54<1:44:16, 284.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 18, Episode Reward: -235.70500364527106, Steps: 18155, Epsilon: 0.1500946352969992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 19/40 [1:11:52<1:40:58, 288.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 19, Episode Reward: -139.6500032087788, Steps: 16890, Epsilon: 0.13508517176729928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 20/40 [1:16:44<1:36:34, 289.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 20, Episode Reward: 61.01999752037227, Steps: 9540, Epsilon: 0.12157665459056936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▎    | 21/40 [1:22:17<1:35:50, 302.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 21, Episode Reward: -734.095005095005, Steps: 63465, Epsilon: 0.10941898913151243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 22/40 [1:27:37<1:32:21, 307.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 22, Episode Reward: 182.1049973508343, Steps: 7946, Epsilon: 0.0984770902183612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▊    | 23/40 [1:32:52<1:27:50, 310.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 23, Episode Reward: -66.63500150013715, Steps: 11820, Epsilon: 0.08862938119652508\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 24/40 [1:38:26<1:24:36, 317.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 24, Episode Reward: -451.70500161033124, Steps: 35694, Epsilon: 0.07976644307687257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 25/40 [1:43:58<1:20:24, 321.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 25, Episode Reward: -273.2400004938245, Steps: 12644, Epsilon: 0.07178979876918531\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 26/40 [1:49:21<1:15:06, 321.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 26, Episode Reward: -348.8099996307865, Steps: 8869, Epsilon: 0.06461081889226679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 27/40 [1:54:52<1:10:21, 324.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 27, Episode Reward: -26.845001183450222, Steps: 15299, Epsilon: 0.05814973700304011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 28/40 [2:00:37<1:06:10, 330.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 28, Episode Reward: -130.81500063464046, Steps: 33954, Epsilon: 0.0523347633027361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▎  | 29/40 [2:06:23<1:01:29, 335.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 29, Episode Reward: -211.9950000019744, Steps: 12663, Epsilon: 0.04710128697246249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 30/40 [2:12:11<56:31, 339.20s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 30, Episode Reward: 50.39499890431762, Steps: 11642, Epsilon: 0.042391158275216244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 31/40 [2:17:55<51:04, 340.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 31, Episode Reward: 75.86499898321927, Steps: 9092, Epsilon: 0.03815204244769462\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 32/40 [2:23:37<45:28, 341.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 32, Episode Reward: 166.22499839682132, Steps: 8312, Epsilon: 0.03433683820292516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▎ | 33/40 [2:29:24<40:00, 342.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 33, Episode Reward: -28.600000829435885, Steps: 11047, Epsilon: 0.030903154382632643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 34/40 [2:35:11<34:24, 344.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 34, Episode Reward: 181.33499837014824, Steps: 6693, Epsilon: 0.02781283894436938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 35/40 [2:40:58<28:43, 344.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 35, Episode Reward: 70.40999890398234, Steps: 6562, Epsilon: 0.025031555049932444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 36/40 [2:46:47<23:04, 346.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 36, Episode Reward: -137.4550003753975, Steps: 8786, Epsilon: 0.0225283995449392\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▎| 37/40 [2:52:39<17:23, 347.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 37, Episode Reward: 136.9599985582754, Steps: 6441, Epsilon: 0.020275559590445278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 38/40 [2:58:33<11:39, 349.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 38, Episode Reward: -315.00999911967665, Steps: 8915, Epsilon: 0.01824800363140075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 39/40 [3:04:33<05:52, 352.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 39, Episode Reward: 70.1149987373501, Steps: 15808, Epsilon: 0.016423203268260675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40/40 [3:10:32<00:00, 285.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Episode 40, Episode Reward: 174.69499843847007, Steps: 6970, Epsilon: 0.014780882941434608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "trainer.policy_dqn"
      ],
      "metadata": {
        "_uuid": "20340d54-e379-4658-8966-10aba213d4b4",
        "_cell_guid": "319983ee-abaa-4bf2-914b-fdcf21d92f88",
        "trusted": true,
        "papermill": {
          "duration": 0.025807,
          "end_time": "2024-11-29T15:18:29.260902",
          "exception": false,
          "start_time": "2024-11-29T15:18:29.235095",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "duJaLq6LsSUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3921aef2-f425-4a7f-eae8-45173a7dcd68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QNetwork(\n",
              "  (cnn): Sequential(\n",
              "    (0): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU()\n",
              "  )\n",
              "  (network): Sequential(\n",
              "    (0): Linear(in_features=405, out_features=120, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=84, out_features=21, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(trainer.policy_dqn.state_dict(), 'blue.pt')"
      ],
      "metadata": {
        "trusted": true,
        "id": "xq5eaQO5sSUt"
      },
      "outputs": [],
      "execution_count": 16
    }
  ]
}